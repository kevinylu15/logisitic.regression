---
title: "Tutorial"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Tutorial}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(logistic.regression)
```

```{r}
set.seed(100)

#Create predictor x variables
n <- 200
x1 <- rnorm(n)
x2 <- rbinom(n, size=1, prob=0.5)

# Define true coefficients
beta_true <- c(Intercept = 0.5, x1 = -1.5, x2 = 0.8)

# Calculate linear predictor
eta <- beta_true["Intercept"] + beta_true["x1"] * x1 + beta_true["x2"] * x2

# Calculate probabilities
p <- 1 / (1 + exp(-eta))

# Generate binary response variable
y <- rbinom(n, size = 1, prob = p)

# Create a data frame
data <- data.frame(y = y, x1 = x1, x2 = factor(x2))

```

```{r}
# Fit the model using my_logistic_regression
model <- my_logregr(y ~ x1 + x2, data)

# View the estimated coefficients
print("Estimated Coefficients:")
print(model$coefficients)

```


Comparing Original GLM and my_glm Function
```{r}
my_logreg_fit = my_logreg(y ~ x1+x2, data)
og_glm_fit = glm(y ~ x1+x2, data, family = binomial)
# Convert my_coefficients to numeric vector and set names
my_coefficients <- as.numeric(my_logreg_fit$coefficients)

# Convert glm_coefficients to numeric vector and set names
glm_coefficients <- as.numeric(coef(og_glm_fit))

coef_comparison <- all.equal(my_coefficients, glm_coefficients, tolerance = 1e-6)
print("Coefficient Comparison:")
print(coef_comparison)

#all.equal(coef(og_glm_fit, my_glm_fit$coefficients))
```

Benchmarking Efficiency
```{r}
bench::mark(glm = glm(y~x, data=data, family = binomial), my_glm_fit, check=FALSE)
```

Unit Tests
```{r}
usethis::use_testthat()
test_that("results", {expect_equal(ceof(og_glm_fit), coef(my_glm_fit))})
devtools::test()
```

